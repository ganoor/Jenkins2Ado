<?xml version="1.1" encoding="UTF-8" standalone="no"?><flow-definition plugin="workflow-job@1326.ve643e00e9220">  <actions>    <org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobAction plugin="pipeline-model-definition@2.2150.v4cfd8916915c"/>    <org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobPropertyTrackerAction plugin="pipeline-model-definition@2.2150.v4cfd8916915c">      <jobProperties>        <string>jenkins.model.BuildDiscarderProperty</string>      </jobProperties>      <triggers/>      <parameters>        <string>UI_branch</string>        <string>License_Required</string>        <string>Storage_location</string>        <string>Latest_dmap_image_version</string>        <string>Build_Image</string>        <string>S3_Bucket</string>        <string>Blob_Storage</string>        <string>Build_Type</string>        <string>Service_pack_version</string>        <string>Minimal_dmap_image_version</string>        <string>sonarSeverities</string>        <string>Container_Name</string>        <string>Backend_branch</string>        <string>sonarTypes</string>      </parameters>      <options/>    </org.jenkinsci.plugins.pipeline.modeldefinition.actions.DeclarativeJobPropertyTrackerAction>  </actions>  <description/>  <keepDependencies>false</keepDependencies>  <properties>    <jenkins.model.BuildDiscarderProperty>      <strategy class="hudson.tasks.LogRotator">        <daysToKeep>-1</daysToKeep>        <numToKeep>10</numToKeep>        <artifactDaysToKeep>-1</artifactDaysToKeep>        <artifactNumToKeep>-1</artifactNumToKeep>      </strategy>    </jenkins.model.BuildDiscarderProperty>    <hudson.model.ParametersDefinitionProperty>      <parameterDefinitions>        <hudson.model.StringParameterDefinition>          <name>UI_branch</name>          <description>Enter the name of the UI branch</description>          <defaultValue>main</defaultValue>          <trim>false</trim>        </hudson.model.StringParameterDefinition>        <hudson.model.StringParameterDefinition>          <name>Backend_branch</name>          <description>Enter the name of the Backend branch</description>          <defaultValue>Development</defaultValue>          <trim>false</trim>        </hudson.model.StringParameterDefinition>        <hudson.model.StringParameterDefinition>          <name>Build_Image</name>          <description>Enter the name of the podman build image which will be used to build binaries</description>          <defaultValue>ngdmapo/dmap_build:v6</defaultValue>          <trim>false</trim>        </hudson.model.StringParameterDefinition>        <hudson.model.StringParameterDefinition>          <name>Container_Name</name>          <description>Enter the name of the container in lower case, example: you can put your name</description>          <trim>false</trim>        </hudson.model.StringParameterDefinition>        <hudson.model.StringParameterDefinition>          <name>Service_pack_version</name>          <description>Enter the version of Service pack. Sample values will be like: 6.3.2.0</description>          <defaultValue>0.0.0.1</defaultValue>          <trim>false</trim>        </hudson.model.StringParameterDefinition>        <hudson.model.StringParameterDefinition>          <name>Latest_dmap_image_version</name>          <description>Enter the latest version of DMAP image. Sample values be like:7.4.2.1</description>          <defaultValue>0.0.0.1</defaultValue>          <trim>false</trim>        </hudson.model.StringParameterDefinition>        <hudson.model.StringParameterDefinition>          <name>Minimal_dmap_image_version</name>          <description>Enter minimum version of DMAP image required to run these binaries. Sample values will be like: 7.4.2.0</description>          <defaultValue>0.0.0.1</defaultValue>          <trim>false</trim>        </hudson.model.StringParameterDefinition>        <hudson.model.ChoiceParameterDefinition>          <name>Storage_location</name>          <description>Enter the storage location to store Service pack which is either in S3 or BLOB</description>          <choices class="java.util.Arrays$ArrayList">            <a class="string-array">              <string>Azure_Blob</string>              <string>AWS_S3</string>              <string>Both</string>            </a>          </choices>        </hudson.model.ChoiceParameterDefinition>        <hudson.model.StringParameterDefinition>          <name>S3_Bucket</name>          <description>Enter the S3 Bucket path for uploading the binaries. Sample values will be like dev: dmap-deployment/dev, qa: dmap-deployment/qa, prod: dmap-deployment/prod</description>          <trim>false</trim>        </hudson.model.StringParameterDefinition>        <hudson.model.StringParameterDefinition>          <name>Blob_Storage</name>          <description>Enter the Blob storage path for uploading the binaries. Sample values will be like dev: dmapdevreleases, qa: dmapqareleases, prod: dmapreleases</description>          <defaultValue>pgd2sdevreleases</defaultValue>          <trim>false</trim>        </hudson.model.StringParameterDefinition>        <hudson.model.ChoiceParameterDefinition>          <name>License_Required</name>          <description>True : then license module will be enabled, False: then license module will be disabled in binaries</description>          <choices class="java.util.Arrays$ArrayList">            <a class="string-array">              <string>True</string>              <string>False</string>            </a>          </choices>        </hudson.model.ChoiceParameterDefinition>        <hudson.model.StringParameterDefinition>          <name>sonarTypes</name>          <description>Enter the sonarQube issue types to certify the build</description>          <defaultValue>VULNERABILITY,BUG,CODE_SMELL</defaultValue>          <trim>false</trim>        </hudson.model.StringParameterDefinition>        <hudson.model.StringParameterDefinition>          <name>sonarSeverities</name>          <description>Enter the sonarQube issue severities to certify the build</description>          <defaultValue>CRITICAL,BLOCKER,MAJOR</defaultValue>          <trim>false</trim>        </hudson.model.StringParameterDefinition>        <hudson.model.ChoiceParameterDefinition>          <name>Build_Type</name>          <description>Select build type</description>          <choices class="java.util.Arrays$ArrayList">            <a class="string-array">              <string>Dev</string>              <string>QA</string>              <string>Prod</string>            </a>          </choices>        </hudson.model.ChoiceParameterDefinition>        <hudson.model.ChoiceParameterDefinition>          <name>Change_in_binary_for</name>          <description>Select App or DB if there is binary change in App or DB respectively, select Both if there is binary change in Both (App and DB)</description>          <choices class="java.util.Arrays$ArrayList">            <a class="string-array">              <string>App</string>              <string>DB</string>              <string>Both</string>            </a>          </choices>        </hudson.model.ChoiceParameterDefinition>      </parameterDefinitions>    </hudson.model.ParametersDefinitionProperty>  </properties>  <definition class="org.jenkinsci.plugins.workflow.cps.CpsScmFlowDefinition" plugin="workflow-cps@3837.v305192405b_c0">    <scm class="hudson.plugins.git.GitSCM" plugin="git@4.3.0">      <configVersion>2</configVersion>      <userRemoteConfigs>        <hudson.plugins.git.UserRemoteConfig>          <url>https://github.com/newtglobalgit/DMAP_Jenkins_Pipelines.git</url>          <credentialsId>Kavya_1709</credentialsId>        </hudson.plugins.git.UserRemoteConfig>      </userRemoteConfigs>      <branches>        <hudson.plugins.git.BranchSpec>          <name>*/scripts_backup</name>        </hudson.plugins.git.BranchSpec>      </branches>      <doGenerateSubmoduleConfigurations>false</doGenerateSubmoduleConfigurations>      <submoduleCfg class="list"/>      <extensions/>    </scm>    <scriptPath>1_PGD2S_Binary_Podman/script.groovy</scriptPath>    <lightweight>true</lightweight>  </definition>  <triggers/>  <disabled>false</disabled><script>// Manually pulled from git based on configurations
pipeline { 	 agent {        node {            label 'build_slave_day2_centos'        }    }	environment {		BUILD_NAME = "Day2Postgres Binary Build"		NOTIFYUSERS = 'pgd2s-devteam@newtglobalcorp.com'		//NOTIFYUSERS = 'sakthip@newtglobalcorp.com'		BUILD_DETAILS = "&lt;BR&gt;Job Name: ${env.JOB_NAME} &lt;BR&gt;Build Number: ${env.BUILD_NUMBER} &lt;BR&gt;Build URL: ${BUILD_URL}"	}	tools {      nodejs "nodejs"    }	parameters {	    string(name: 'UI_branch', defaultValue: 'main', description: 'Enter the name of the UI branch')	    string(name: 'Backend_branch', defaultValue: 'Development', description: 'Enter the name of the Backend branch')	    string(name: 'Build_Image', defaultValue: 'ngdmapo/dmap_build:v6', description: 'Enter the name of the podman build image which will be used to build binaries')        string(name: 'Container_Name', defaultValue: '', description: 'Enter the name of the container in lower case, example: you can put your name')        string(name: 'Service_pack_version', defaultValue: '0.0.0.1', description: 'Enter the version of Service pack. Sample values will be like: 6.3.2.0')        string(name: 'Latest_dmap_image_version', defaultValue: '0.0.0.1', description: 'Enter the latest version of DMAP image. Sample values be like:7.4.2.1')        string(name: 'Minimal_dmap_image_version', defaultValue: '0.0.0.1', description: 'Enter minimum version of DMAP image required to run these binaries. Sample values will be like: 7.4.2.0')        choice(name: 'Storage_location', choices: ['Azure_Blob','AWS_S3','Both'], description: 'Enter the storage location to store Service pack which is either in S3 or BLOB')		string(name: 'S3_Bucket', defaultValue: '', description: 'Enter the S3 Bucket path for uploading the binaries. Sample values will be like dev: dmap-deployment/dev, qa: dmap-deployment/qa, prod: dmap-deployment/prod')		string(name: 'Blob_Storage', defaultValue: 'pgd2sdevreleases', description: 'Enter the Blob storage path for uploading the binaries. Sample values will be like dev: dmapdevreleases, qa: dmapqareleases, prod: dmapreleases')		choice(name: 'License_Required', choices: ['True', 'False'], description: 'True : then license module will be enabled, False: then license module will be disabled in binaries')		string(name: 'sonarTypes', defaultValue: 'VULNERABILITY,BUG,CODE_SMELL', description: 'Enter the sonarQube issue types to certify the build')        string(name: 'sonarSeverities', defaultValue: 'CRITICAL,BLOCKER,MAJOR', description: 'Enter the sonarQube issue severities to certify the build')        choice(name: 'Build_Type', choices: ['Dev', 'QA','Prod'], description: 'Select build type')    }	options {        timestamps()        timeout(time: 12, unit: 'HOURS')        buildDiscarder(logRotator(numToKeepStr: '10'))    }	stages {		stage ("Checkout Code") {			steps {			    deleteDir()			    dir("UI"){			        deleteDir()				    echo "Checkout the UI code"				    git branch: "${params.UI_branch}", credentialsId: 'Kavya_1709', url: 'https://github.com/newtglobalgit/PostgreSQL-Automation.git'			    }			    dir("Backend"){			        deleteDir()				    echo "Checkout the Backend code"				    git branch: "${params.Backend_branch}", credentialsId: 'Kavya_1709', url: 'https://github.com/newtglobalgit/PostgreSQL-Automation_Backend.git'			    }			}		}        stage ("Sonar Analysis") {    			steps{    			    echo "Backend sonar Analysis"    			    dir("Backend"){    			         sh "/opt/sonar-scanner/sonar-scanner/bin/sonar-scanner \        				-Dsonar.projectKey=day2supportpg_backend \        				-Dsonar.projectName=day2supportpg_backend \        				-Dsonar.sources=. \        				-Dsonar.host.url=http://192.168.3.148:9000/sonarqube\        				-Dsonar.login=25534cb4ff60d377ca72aefd244d70eff8bfcf56"    			    }    			    echo "UI sonar Analysis"    			     dir("UI"){    			         sh "npm install --force"    			        sh "/opt/sonar-scanner/sonar-scanner/bin/sonar-scanner \        				-Dsonar.projectKey=day2supportpg_UI \        				-Dsonar.projectName=day2supportpg_UI \        				-Dsonar.sources=src/ \        				-Dsonar.exclusions=node_modules/ \        				-Dsonar.host.url=http://192.168.3.148:9000/sonarqube \        				-Dsonar.login=25534cb4ff60d377ca72aefd244d70eff8bfcf56"    			    }     			}    		} 		stage ("UI Tests"){			steps{			    dir("UI"){				    echo "Started Snyk Tests"				    snykSecurity failOnIssues: false, snykInstallation: 'SnykV2PluginTest', snykTokenId: 'Snyk_API'				    //sh "npm install --save xmlhttprequest"					echo "Running Sonar Analysis"				    //sh "cd SonarQube; node sonar.ts 192.168.3.148 9000/sonarqube ${params.sonarTypes} ${params.sonarSeverities} | tee output.log"					//sh "mv SonarQube/sonarAnalysis.html SonarQube/UISonarQualityGateCheck.html"					sh "mv UI_snyk_report.html UISnykReport.html"		//		    sh '! grep "SonarQube Failed" SonarQube/output.log'				   // publishHTML([allowMissing: false, alwaysLinkToLastBuild: false, keepAll: false, reportDir: 'SonarQube', reportFiles: 'UISonarQualityGateCheck.html', reportName: 'UI SonarQube Analysis Result', reportTitles: 'SonarQube Result'])				    publishHTML([allowMissing: false, alwaysLinkToLastBuild: false, keepAll: true, reportDir: '.', reportFiles: 'UISnykReport.html', reportName: 'Snyk Result', reportTitles: 'Snyk Result'])			    }			}		}		stage ("UI Build") {			steps {			    dir("UI"){				    echo "Building the UI code"				    sh "npm install --force"				    sh "ng build --configuration production --base-href=/db-automation/"				    dir("dist"){				        sh "tar -cvf PGDAY2.tar db-automation/"				        sh "cp PGDAY2.tar ../.."				    }			    }			}		}		stage ("Backend Tests") {			steps {			    echo "Running Bandit"			    dir("Backend") {					echo "Running Bandit"					sh "bandit -r ./ -x ./Deploy -ll -f csv -o PythonBanditAnalysisReport.csv || true"					echo "Running Sonar Analysis"					sh "cd SonarQube; python TestSonar.py -I 192.168.3.148 -P 9000/sonarqube -T ${params.sonarTypes} -S ${params.sonarSeverities} | tee output.log"					sh "mv SonarQube/sonarAnalysis.html SonarQube/BackendSonarQualityGateCheck.html"					echo "Running pytest and coverage"					//sh "cd Tests; pytest Test.py"					//sh "mv Tests/htmlcov/index.html Tests/htmlcov/ConstructTestCoverageReport.html"					//sh "mv Tests/summary.html Tests/ConstructTestOutput.html"					// sh '! grep "SonarQube Failed" SonarQube/output.log'					publishHTML([allowMissing: false, alwaysLinkToLastBuild: false, keepAll: true, reportDir: '.', reportFiles: 'PythonBanditAnalysisReport.csv', reportName: 'Bandit Security Report', reportTitles: 'Bandit Security Report'])					//publishHTML([allowMissing: false, alwaysLinkToLastBuild: false, keepAll: true, reportDir: '.\\Tests', reportFiles: 'ConstructTestOutput.html', reportName: 'Construct PyTest Result', reportTitles: 'Construct PyTest Result'])					//publishHTML([allowMissing: false, alwaysLinkToLastBuild: false, keepAll: true, reportDir: '.\\Tests\\htmlcov', reportFiles: 'ConstructTestCoverageReport.html', reportName: 'Construct Coverage Result', reportTitles: 'Construct Coverage Result'])					publishHTML([allowMissing: false, alwaysLinkToLastBuild: false, keepAll: true, reportDir: '.\\SonarQube', reportFiles: 'BackendSonarQualityGateCheck.html', reportName: 'Backend SonarQube Analysis Result', reportTitles: 'Backend SonarQube Analysis Result'])					publishHTML([allowMissing: false, alwaysLinkToLastBuild: false, keepAll: true, reportDir: '.\\SonarQube', reportFiles: 'Backend_Sonar_Issues.xlsx', reportName: 'Sonar Backend Excel Report', reportTitles: 'Sonar Backend Excel Report'])					publishHTML([allowMissing: false, alwaysLinkToLastBuild: false, keepAll: true, reportDir: '.\\SonarQube', reportFiles: 'Frontend_Sonar_Issues.xlsx', reportName: 'Sonar Frontend Excel Result', reportTitles: 'Sonar Frontend Excel Result'])				}			}		}		stage ("Backend Build") {			steps {				echo "---------------------Creating build container---------------------------"				sh "podman images"				sh "podman pull docker.io/ngdmapo/dmap_build:v6"				withCredentials([string(credentialsId: 'GIT_User', variable: 'GITUser'),string(credentialsId: 'Git_New_PAT', variable: 'Password')]) {                    sh "podman run -d -it -e GIT_USER=${GITUser} -e GIT_PASS=${Password} -e GIT_BRANCH=${params.Backend_branch} -e LICENSE_REQUIRED=${params.License_Required} --name=${params.Container_Name} ${params.Build_Image}"                }				echo "---------------------Completed creating build container---------------------------"			    dir("Backend") {					echo "------------------Build container created-------------------------------"					sh "podman ps -a"					sh "podman cp BuildScript/make_backend.sh ${params.Container_Name}:/usr/local/tomcat"					echo "------------Copied build scipt inside build container------------------"					sh "podman exec ${params.Container_Name} sh /usr/local/tomcat/make_backend.sh"					echo "----------------------------Binaries created-------------------------------"					sh "podman cp ${params.Container_Name}:/usr/local/tomcat/PostgreSQL-Automation_Backend/dist/Service.tar ."					echo "------------------------Copied binaries in Jenkins----------------------"					sh "cp Service.tar ../"			    }				echo "------------------Removing Build container ------------------"				sh "podman stop ${params.Container_Name}"			    sh "podman rm -f ${params.Container_Name}"			    echo "------------------Build container removed successfully------------------"			 }		}		/*		stage ("Modular Tests") {		    steps {				echo "---------------------Creating build container for modular test---------------------------"				sh "docker run -d -it -p 8085:8080 -p 5003:5002 -e UI_PORT=8085 -e SERVICE_PORT=5003 --name=run_modular_test_scripts ngdmapo/dmap_azure_blob_dev:v7.6.0.0"				echo "------------------Wait 40 minutes to start backend-------------------------------"				sleep 900				dir("Backend"){					sh "docker ps -a"					sh "docker cp run_modularTest.sh run_modular_test_scripts:/usr/local/tomcat"					echo "------------Copied modular test build script inside build container------------------"					sh "docker exec run_modular_test_scripts sh /usr/local/tomcat/run_modularTest.sh"					sleep 600					echo "------------Copying modular test cases reports------------------"					sh "docker cp run_modular_test_scripts:/usr/local/tomcat/DMAP_Backend/ModularityTesting/ModularTestOutput.html ."					sh "docker cp run_modular_test_scripts:/usr/local/tomcat/DMAP_Backend/htmlcov/index.html ."					sh "mv index.html ModularTestCoverageReport.html"					echo "------------Completed copying modular test cases reports------------------"					echo "------------Removing modular test container ------------------"					sh "docker stop run_modular_test_scripts"					sh "docker rm -f run_modular_test_scripts"					echo "------------Modular test container removed successfully------------------"					publishHTML([allowMissing: false, alwaysLinkToLastBuild: false, keepAll: true, reportDir: '.', reportFiles: 'ModularTestOutput.html', reportName: 'Modular Test Output', reportTitles: 'Modular Test Output'])					publishHTML([allowMissing: false, alwaysLinkToLastBuild: false, keepAll: true, reportDir: '.', reportFiles: 'ModularTestCoverageReport.html', reportName: 'Modular Test Coverage', reportTitles: 'Modular Test Coverage'])				}			}		}		stage ("API Test") {		    steps {				echo "---------------------Creating build container for API test---------------------------"				sh "docker run -d -it -p 8086:8080 -p 5004:5002 -e UI_PORT=8086 -e SERVICE_PORT=5004 --name=run_api_test_scripts ngdmapo/dmap_azure_blob_dev:v7.6.0.0"				echo "------------------Wait 40 minutes to start backend-------------------------------"				sleep 900				sh "docker ps -a"				echo "------------Copy kill_remove_service script----------------"				sh "docker cp Backend/kill_remove_service.sh run_api_test_scripts:/usr/local/tomcat"				echo "------------Run kill_remove_service script----------------"				sh "docker exec run_api_test_scripts sh /usr/local/tomcat/kill_remove_service.sh"				echo "------------Copy untar_service script----------------"				sh "docker cp Backend/untar_service.sh run_api_test_scripts:/usr/local/tomcat"				echo "------------Copy newly built backend binary into container---------------"				sh "docker cp Service.tar run_api_test_scripts:/usr/local/tomcat"				echo "------------Run untar_service script-----------------"				sh "docker exec run_api_test_scripts sh /usr/local/tomcat/untar_service.sh"				echo "------------Restarting api test container---------------"				sh "docker restart run_api_test_scripts" 				echo "------------------Wait 30 seconds to start backend services-------------------------------"				sleep 900				dir("API"){					echo "------------------------Running testcases--------------------------------"					sh "mvn -f RestAssured clean test"					sleep 30					sh "mv RestAssured/target/surefire-reports/emailable-report.html ApiTestReport.html"					echo "------------Removing API test container ------------------"					sh "docker stop run_api_test_scripts"					sh "docker rm -f run_api_test_scripts"					echo "------------API test container removed successfully------------------"					publishHTML([allowMissing: false, alwaysLinkToLastBuild: false, keepAll: true, reportDir: '.', reportFiles: 'ApiTestReport.html', reportName: 'API Test Output', reportTitles: 'API Test Output'])				}			}		}*/		stage ("Package Binary") {			steps {			    echo "------------------Package Binary------------------"			    script {			      def now = new Date()			      def time = now.format("yyyy-MM-dd HH:mm:ss", TimeZone.getTimeZone('UTC'))			      writeFile(file: 'pgd2s_release.yaml', text:"product_name: PGD2S\nbinary_version: ${params.Service_pack_version}\nminimal_supported_image_version: ${params.Minimal_dmap_image_version}\ndate_published: ${time}\nbuild_type: ${params.Build_Type}")			      sh "tar cvf pgd2s_release.tar PGDAY2.tar Service.tar pgd2s_release.yaml"			    }			}		}		stage ("S3 Bucket Upload"){		    when {                      expression { params.Storage_location == "AWS_S3" || params.Storage_location == "Both" }                }			steps {				echo "---------------Deploying Artifacts to S3 Bucket--------------"				script {				    def now = new Date()			        def time = now.format("yyyy-MM-dd HH:mm:ss", TimeZone.getTimeZone('UTC'))				    def values = "${params.S3_Bucket}".split('/')					sh "echo \$(md5sum pgd2s_release.tar | cut -d ' ' -f1) &gt;&gt; dmap_tar_checksum.txt"			        sh "echo \$(stat -c \"%n,%s\" pgd2s_release.tar | column -s, | cut -d ',' -f2) &gt;&gt; dmap_tar_filesize.txt"			        def md5sum = readFile(file: 'dmap_tar_checksum.txt')			        def filesize = readFile(file: 'dmap_tar_filesize.txt')					sh "rm -rf dmap_tar_checksum.txt"			        sh "rm -rf dmap_tar_filesize.txt"    			    writeFile(file: 'pgd2s_latest_release_info.yaml', text:"product_name: PGD2S\nlatest_image_version: ${params.Latest_dmap_image_version}\nlatest_binary_version: ${params.Service_pack_version}\nminimal_supported_image_version: ${params.Minimal_dmap_image_version}\ndate_published: ${time}\nchecksum: ${md5sum}filesize: ${filesize}url_to_download_dmap_binary: https://dmap-deployment.s3.ap-south-1.amazonaws.com/${values[1]}/")				}				withCredentials([[$class: 'AmazonWebServicesCredentialsBinding', accessKeyVariable: 'AWS_ACCESS_KEY_ID', credentialsId: 'DMAP_AWS', secretKeyVariable: 'AWS_SECRET_ACCESS_KEY']]) {					sh "aws s3 cp pgd2s_latest_release_info.yaml s3://${params.S3_Bucket}/ --acl public-read"					sh "aws s3 cp pgd2s_release.tar s3://${params.S3_Bucket}/ --acl public-read"				}			}		}		stage ("Blob Storage Upload"){		    when {                expression { params.Storage_location == "Azure_Blob" || params.Storage_location == "Both" }            }			steps {				echo "---------------Deploying Artifacts to Blob Storage--------------"				script {				    echo "Azure Blob Service Pack"				    def now = new Date()			        def time = now.format("yyyy-MM-dd HH:mm:ss", TimeZone.getTimeZone('UTC'))					sh "echo \$(md5sum pgd2s_release.tar | cut -d ' ' -f1) &gt;&gt; dmap_tar_checksum.txt"			        sh "echo \$(stat -c \"%n,%s\" pgd2s_release.tar | column -s, | cut -d ',' -f2) &gt;&gt; dmap_tar_filesize.txt"			        def md5sum = readFile(file: 'dmap_tar_checksum.txt')			        def filesize = readFile(file: 'dmap_tar_filesize.txt')					sh "rm -rf dmap_tar_checksum.txt"			        sh "rm -rf dmap_tar_filesize.txt"			        writeFile(file: 'pgd2s_latest_release_info.yaml', text:"product_name: PGD2S\nlatest_image_version: ${params.Latest_dmap_image_version}\nlatest_binary_version: ${params.Service_pack_version}\nChange_in_binary_for: ${params.Change_in_binary_for}\nminimal_supported_image_version: ${params.Minimal_dmap_image_version}\ndate_published: ${time}\nchecksum: ${md5sum}filesize: ${filesize}url_to_download_dmap_binary: https://msmkdmapdisks.blob.core.windows.net/${params.Blob_Storage}/")				}				withCredentials([string(credentialsId: 'BlobAccountKey', variable: 'BlobAccountKey')]) {				    sh "/home/newtdba/bin/az storage blob upload --account-name msmkdmapdisks --account-key ${BlobAccountKey} --container-name ${params.Blob_Storage} --file pgd2s_release.tar --name pgd2s_release.tar --overwrite"                    sh "/home/newtdba/bin/az storage blob upload --account-name msmkdmapdisks --account-key ${BlobAccountKey} --container-name ${params.Blob_Storage} --file pgd2s_latest_release_info.yaml --name pgd2s_latest_release_info.yaml --overwrite"                }			}		}	}	post {        always {            emailext attachmentsPattern: 'Backend/Tests/htmlcov/ConstructTestCoverageReport.html, Backend/Tests/ConstructTestOutput.html, Backend/PythonBanditAnalysisReport.csv, Backend/SonarQube/BackendSonarQualityGateCheck.html,UI/UISnykReport.html,Backend/SonarQube/Day2PG_Frontend_Sonar_Issues.xlsx,Backend/SonarQube/Day2PG_Backend_Sonar_Issues.xlsx',            subject: "Jenkins Job Report For ${BUILD_NAME} - ${currentBuild.currentResult}",			body: "BUILD DETAILS: ${BUILD_DETAILS} &lt;BR&gt; BUILD STATUS: ${currentBuild.currentResult}",			to: "${NOTIFYUSERS}"        }		success {            // Triggering additional builds after the current build is successful            build job: '8_PGD2S_Selenium_Robot_Suite', parameters: [string(name: 'Ip', value: 'localhost'),string(name: 'PORT', value: '5002'),string(name: 'DB_Docker_Image', value: "docker.io/ngdmapo/pgd2s_azure_blob_docker_dev:v${params.Latest_dmap_image_version}")], wait: false			build job: '7_PGD2S_APP_Modularity_Test_Cases', parameters: [string(name: 'PGD2S_Backend_branch', value: 'Development'),string(name: 'PGD2S_Docker_Image', value: "docker.io/ngdmapo/pgd2s_azure_blob_docker_dev:v${params.Latest_dmap_image_version}")], wait: false			build job: '6_PGD2S_RestAssured_Test_Cases', parameters: [string(name: 'Ip', value: 'localhost'),string(name: 'PORT', value: '5002'),string(name: 'DB_Docker_Image', value: "docker.io/ngdmapo/pgd2s_azure_blob_docker_dev:v${params.Latest_dmap_image_version}")], wait: false			build job: '7_PGD2S_PYTEST_Test_Cases', parameters: [string(name: 'Ip', value: 'localhost'),string(name: 'PORT', value: '5002'),string(name: 'DB_Docker_Image', value: "docker.io/ngdmapo/pgd2s_azure_blob_docker_dev:v${params.Latest_dmap_image_version}")], wait: false        }    }}</script></flow-definition>